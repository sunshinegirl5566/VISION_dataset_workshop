{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP classification - supervised learning\n",
    "\n",
    "In this example, you will learn how you can use supervised learning algorithms for NLP classification. We will use documents from https://www.reddit.com/r/domesticviolence/ and https://www.reddit.com/r/emotionalabuse/ The task is to classify a document into two different types of violence: violence or not.\n",
    "\n",
    "We will use classification algorithms as implemented in sci-kit learn, and evaluate with cross-validation before testing on unseen test data.\n",
    "\n",
    "We will experiment with different ways of representing the documents for the classifiers.\n",
    "\n",
    "material in parts from https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "\n",
    "Written by Sumithra Velupillai, March 2019 - updated February 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "try:\n",
    "    import xlrd\n",
    "except ImportError as e:\n",
    "    !pip install xlrd\n",
    "    import xlrd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use scikit-learn for the classification algorithms.\n",
    "# https://scikit-learn.org/stable/\n",
    "\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sklearn also has some nice funtions for representations\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## and for evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we're working with text, we might need to tokenize for some of these representations. \n",
    "# We'll use nltk here, but there are other nlp packages available for this\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have also learnt about embedding representations. These can also be used for classification.\n",
    "# We will use a library called Zeugma, which allows using pre-trained embedding models\n",
    "#Zeugma library: https://github.com/nkthiebaut/zeugma\n",
    "\n",
    "try:\n",
    "    from zeugma.embeddings import EmbeddingTransformer\n",
    "except ImportError as e:\n",
    "    !pip install zeugma\n",
    "    !pip install theano\n",
    "    from zeugma.embeddings import EmbeddingTransformer\n",
    "\n",
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Corpus \n",
    "Reading in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the whole dataset - we will fetch it from git\n",
    "!git clone --quiet https://github.com/KHP-Informatics/vision.git\n",
    "data_dir='/content/vision/dataset-workshop/practicals/'\n",
    "\n",
    "data= pd.read_csv(data_dir + 'violence_data_900_sample.csv')\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "print(data.describe())\n",
    "data=data[['label','selftext']]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test data\n",
    "'''\n",
    "We may use train_test_split method in sklearn\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data['selftext']\n",
    "y=data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingdata= pd.concat([X_train, pd.DataFrame(y_train)], axis=1)\n",
    "print(trainingdata.shape)\n",
    "\n",
    "print(trainingdata.columns)\n",
    "print(trainingdata['label'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have done some mannual labeled data, we will combine those labeled data and use them as the test data\n",
    "\n",
    "# 1, re-read training data\n",
    "trainingdata= data\n",
    "print(trainingdata.shape)\n",
    "# 2, generate test data from different coders' labeled data\n",
    "coderA= pd.DataFrame()\n",
    "# change the number\n",
    "coder_num = 2\n",
    "for i in range(1,coder_num+1):\n",
    "    df = pd.read_csv(data_dir + 'Sample_data'+str(i)+'_to_label_A.csv')\n",
    "    coderA=coderA.append(df)\n",
    "print(coderA.shape)\n",
    "print(coderA.head())\n",
    "\n",
    "coderB= pd.DataFrame()\n",
    "for i in range(1,coder_num+1):\n",
    "    df = pd.read_csv(data_dir + 'Sample_data'+str(i)+'_to_label_B.csv')\n",
    "    coderB=coderB.append(df)\n",
    "print(coderB.shape)\n",
    "print(coderB.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inter-Annotator Agreement (IAA), a measure of how well multiple annotators can make the same annotation decision for a certain category. Supervised Natural Language Processing algorithms use a labeled dataset, that is often annotated by humans. Here, it would be the annotation scheme for this workshop, where posts were labeled as either violence or non-violence (based on selftext).\n",
    "\n",
    "Pair-wise Cohen kappa and group Fleissâ€™ kappa (ðœ…) coefficients can be applied, we will use Cohen kappa here.\n",
    "For other details, please refer to this link: https://towardsdatascience.com/inter-annotator-agreement-2f46c6d37bf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate coderA and coderB's IAA, in this edition, I just tried the first sample data by myself\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "labelerA = coderA['label']\n",
    "labelerB = coderB['label']\n",
    "IAA_AB=cohen_kappa_score(labelerA, labelerB)\n",
    "print(IAA_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='kappa.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Viera, A. J., & Garrett, J. M. (2005). \n",
    "Understanding interobserver agreement: the kappa statistic. \n",
    "Fam med, 37(5), 360-363. \n",
    "\n",
    "cited:7812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Representation - BoW\n",
    "The most common baseline feature representation for text classification tasks is to use the bag-of-words representation, in a document-term matrix. Let's build a simple one using raw counts and only keeping a maximum of 500 features. We can use the CountVectorizer function from sklearn, and tokenize using a function from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vectorizer = CountVectorizer(ngram_range=(1,1), stop_words=None,\n",
    "                             tokenizer=word_tokenize, max_features=500)\n",
    "first_vectorizer.fit(trainingdata['selftext'].tolist())\n",
    "first_fit_transformed_data = first_vectorizer.fit_transform(trainingdata['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What word is represented by the different indices? Have a look at a few examples.\n",
    "print (first_vectorizer.get_feature_names()[32])\n",
    "print(first_fit_transformed_data.shape)\n",
    "print ('Amount of Non-Zero occurences: ', first_fit_transformed_data.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Classification\n",
    "Let's build a classifier with this feature representation. In text classification, many classification algorithms have been shown to work well. Sci-kit learn has implementations for many different types of classification algorithms - have a look at their website!\n",
    "\n",
    "Let's try a K nearest neighbour classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#kneighbour_classifier = KNeighborsClassifier().fit(first_fit_transformed_data, trainingdata['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model. But how do we know how well it works? Let's evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata= pd.concat([X_test, pd.DataFrame(y_test)], axis=1)\n",
    "print(testdata.shape)\n",
    "testdata['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we try to use the labeled data as follows:\n",
    "print(coderA.columns)\n",
    "print(coderB.columns)\n",
    "new_df = pd.merge(coderA,coderB,on='index')\n",
    "print(new_df.columns) # ['label_x', 'selftext_x', 'index', 'label_y', 'selftext_y']\n",
    "print(coderA.shape,coderB.shape,new_df.shape)\n",
    "same_df = new_df[new_df['label_x']==new_df['label_y']]\n",
    "print(same_df.shape)\n",
    "\n",
    "diff_df = pd.concat([new_df,same_df]).drop_duplicates(keep=False)\n",
    "print(diff_df['index'])\n",
    "print(diff_df.shape)\n",
    "print(diff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to re-label the rest data if the cohen's Kappa value is not reasonable. \n",
    "# Here we just assmue that, we agree with coder B's results, then:\n",
    "testdata = new_df[['index', 'label_y', 'selftext_y']]\n",
    "testdata = testdata.rename(columns={\"label_y\": \"label\", 'selftext_y':'selftext'})\n",
    "print(testdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to transform this data to the same representation\n",
    "first_fit_transformed_testdata = first_vectorizer.transform(testdata['selftext'])\n",
    "kneighbour_classifier = KNeighborsClassifier().fit(first_fit_transformed_data, trainingdata['label'])\n",
    "print(first_fit_transformed_testdata)\n",
    "kneighbour_predicted = kneighbour_classifier.predict(first_fit_transformed_testdata)\n",
    "print(kneighbour_predicted)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testdata['label'],kneighbour_predicted ))\n",
    "#print(metrics.classification_report(testdata['label'], kneighbour_predicted, target_names=set(testdata['label'].tolist())))\n",
    "#print(metrics.classification_report(testdata['label'], kneighbour_predicted, target_names=set(testdata['label'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "x_axis_labels = ['Not violence','violence'] # labels for x-axis\n",
    "y_axis_labels = ['Not violence','violence'] # labels for y-axis\n",
    "\n",
    "cm =confusion_matrix(testdata['label'], kneighbour_predicted)\n",
    "cm_plot = sns.heatmap(cm, cmap=\"YlGnBu\",annot=True, fmt=\"d\",xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use some other classifiers to check which one is better:RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier = RandomForestClassifier().fit(first_fit_transformed_data, trainingdata['label'])\n",
    "\n",
    "first_fit_transformed_testdata = first_vectorizer.transform(testdata['selftext'])\n",
    "print(first_fit_transformed_testdata)\n",
    "RandomForestClassifier_predicted = RandomForestClassifier.predict(first_fit_transformed_testdata)\n",
    "print(RandomForestClassifier_predicted)\n",
    "#print(metrics.classification_report(testdata['label'], RandomForestClassifier_predicted, target_names=set(testdata['label'].tolist())))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testdata['label'], RandomForestClassifier_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try other classifiers by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x_axis_labels = ['Not violence','violence'] # labels for x-axis\n",
    "y_axis_labels = ['Not violence','violence'] # labels for y-axis\n",
    "\n",
    "cm =confusion_matrix(testdata['label'], RandomForestClassifier_predicted)\n",
    "cm_plot = sns.heatmap(cm, cmap=\"YlGnBu\",annot=True, fmt=\"d\",xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to transform this data to the same representation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier = DecisionTreeClassifier().fit(first_fit_transformed_data, trainingdata['label'])\n",
    "first_fit_transformed_testdata = first_vectorizer.transform(testdata['selftext'])\n",
    "print(first_fit_transformed_testdata)\n",
    "DecisionTree_predicted = DecisionTreeClassifier.predict(first_fit_transformed_testdata)\n",
    "print(DecisionTree_predicted)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testdata['label'], DecisionTree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x_axis_labels = ['Not violence','violence'] # labels for x-axis\n",
    "y_axis_labels = ['Not violence','violence'] # labels for y-axis\n",
    "\n",
    "cm =confusion_matrix(testdata['label'], DecisionTree_predicted)\n",
    "cm_plot = sns.heatmap(cm, cmap=\"YlGnBu\",annot=True, fmt=\"d\",xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: N-fold cross-validation\n",
    "We can employ n-fold cross-validation on the training data to experiment with different representations, parameters, and classifiers.\n",
    "There are also various metrics that can be used to evaluate classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0).fit(first_fit_transformed_data, trainingdata['label'])\n",
    "scoring = ['precision_macro', 'recall_macro','precision_micro','recall_micro', 'f1_micro', 'f1_macro']\n",
    "scores = cross_validate(rf_classifier, first_fit_transformed_data, trainingdata['label'], scoring=scoring, cv=10, return_train_score=False)\n",
    "scoresdf = pd.DataFrame(scores)\n",
    "scoring = ['test_precision_macro', 'test_recall_macro','test_precision_micro','test_recall_micro', 'test_f1_micro', 'test_f1_macro']\n",
    "bp = scoresdf.boxplot(column=scoring, grid=False, rot=45,)\n",
    "[ax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)]\n",
    "fig = np.asarray(bp).reshape(-1)[0].get_figure()\n",
    "fig.suptitle('Random forest, count vectorizer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Another representation model: Tf-idfÂ¶\n",
    "We have used a very simple bag-of-words representation.\n",
    " What happens if we try something else? Let's try tf-idf. \n",
    " This is considered a strong baseline in many text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopWords)\n",
    "tfidf_vect.fit(trainingdata['selftext'])\n",
    "second_fit_transformed_data =  tfidf_vect.transform(trainingdata['selftext'])\n",
    "second_fit_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier2 = RandomForestClassifier().fit(second_fit_transformed_data, trainingdata['label'])\n",
    "scoring = ['precision_macro', 'recall_macro','precision_micro','recall_micro', 'f1_micro', 'f1_macro']\n",
    "scores = cross_validate(rf_classifier2, second_fit_transformed_data, trainingdata['label'], scoring=scoring, cv=10, return_train_score=False)\n",
    "scoresdf = pd.DataFrame(scores)\n",
    "scoring = ['test_precision_macro', 'test_recall_macro','test_precision_micro','test_recall_micro', 'test_f1_micro', 'test_f1_macro']\n",
    "bp = scoresdf.boxplot(column=scoring, grid=False, rot=45,)\n",
    "[ax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)]\n",
    "fig = np.asarray(bp).reshape(-1)[0].get_figure()\n",
    "fig.suptitle('Random forest, tf-idf vectorizer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier2 = DecisionTreeClassifier().fit(second_fit_transformed_data, trainingdata['label'])\n",
    "scoring = ['precision_macro', 'recall_macro','precision_micro','recall_micro', 'f1_micro', 'f1_macro']\n",
    "scores = cross_validate(DecisionTreeClassifier2, second_fit_transformed_data, trainingdata['label'], scoring=scoring, cv=10, return_train_score=False)\n",
    "scoresdf = pd.DataFrame(scores)\n",
    "scoring = ['test_precision_macro', 'test_recall_macro','test_precision_micro','test_recall_micro', 'test_f1_micro', 'test_f1_macro']\n",
    "bp = scoresdf.boxplot(column=scoring, grid=False, rot=45,)\n",
    "[ax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)]\n",
    "fig = np.asarray(bp).reshape(-1)[0].get_figure()\n",
    "fig.suptitle('DecisionTreeClassifier, tf-idf vectorizer')\n",
    "plt.show()\n",
    "# We can see that the DecisionTreeClassifier performs pretty good in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figures, we can see that the performance of the applied classifiers:\n",
    " Random Forest classifier with TF-IDF > Random Forest> KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7: Representations: embeddings\n",
    "For the embedding representations.\n",
    "\n",
    "We will try Zeugma which is a package where you can use embeddings in sklearn. https://github.com/nkthiebaut/zeugma\n",
    "\n",
    "It allows you to directly download pre-trained models that have been released from the gensim website.\n",
    "\n",
    "Let's use a basic glove model. \n",
    " \n",
    "We will check what might be the benefit of using this type of representation instead of counts or tf-idf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = EmbeddingTransformer('glove')\n",
    "glove_transformed_training_data = glove.transform(trainingdata['selftext'])\n",
    "print(glove_transformed_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier = DecisionTreeClassifier().fit(glove_transformed_training_data, trainingdata['label'])\n",
    "scoring = ['precision_macro', 'recall_macro','precision_micro','recall_micro', 'f1_micro', 'f1_macro']\n",
    "scores = cross_validate(DecisionTreeClassifier, glove_transformed_training_data, trainingdata['label'], scoring=scoring, cv=10, return_train_score=False)\n",
    "scoresdf = pd.DataFrame(scores)\n",
    "scoring = ['test_precision_macro', 'test_recall_macro','test_precision_micro','test_recall_micro', 'test_f1_micro', 'test_f1_macro']\n",
    "bp = scoresdf.boxplot(column=scoring, grid=False, rot=45,)\n",
    "[ax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)]\n",
    "fig = np.asarray(bp).reshape(-1)[0].get_figure()\n",
    "fig.suptitle('DecisionTree, pre-trained embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Classifiers, representations, evaluation\n",
    "You've now seen that you get very different results depending on which representation you use, which classifier, and also that there are many different metrics to analyse.\n",
    "\n",
    "Let's try some different configurations all in one go. We'll create a dictionary with the three different types of representations, and a list of different classification algorithms, and apply all these configurations to see what seems to yield best results according to a chosen evaluation metric using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "representations = {}\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), stop_words=None,\n",
    "                             tokenizer=word_tokenize, max_features=500)\n",
    "xtrain_countvect = vectorizer.fit_transform(trainingdata['selftext'])\n",
    "representations['CountVectorizer'] = xtrain_countvect\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopWords)\n",
    "tfidf_vect.fit(trainingdata['selftext'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(trainingdata['selftext'])\n",
    "representations['TfidfVectorizer'] = xtrain_tfidf\n",
    "\n",
    "x_train_glove = glove.transform(trainingdata['selftext'])\n",
    "representations['pretrained_glove'] = x_train_glove\n",
    "\n",
    "\n",
    "\n",
    "CV = 10\n",
    "\n",
    "classifier_models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        DecisionTreeClassifier(),\n",
    "        SVC(),\n",
    "     #    LinearSVC(multi_class='ovr', C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "     # intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     #  penalty='l2', random_state=0, tol=1e-05, verbose=0),\n",
    "        SGDClassifier(),\n",
    "        LogisticRegression(random_state=0),\n",
    "        KNeighborsClassifier(),\n",
    "]\n",
    "\n",
    "cv_df = pd.DataFrame(index=range(CV * (len(classifier_models)*len(representations))))\n",
    "entries = []\n",
    "\n",
    "for representation, transformed_vector in representations.items():\n",
    "    score = 'f1_micro'\n",
    "    for model in classifier_models:\n",
    "      model_name = model.__class__.__name__+'_'+representation\n",
    "      accuracies = cross_val_score(model, transformed_vector, trainingdata['label'], scoring=score, cv=CV)\n",
    "      #accuracies = cross_val_score(model, transformed_vector, trainingdata['role'], scoring=score, cv=CV)\n",
    "      for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', score])\n",
    "bp = cv_df.boxplot(by='model_name', column=[score], grid=False, rot=90, figsize=(12,8))\n",
    "[ax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)]\n",
    "fig = np.asarray(bp).reshape(-1)[0].get_figure()\n",
    "fig.suptitle('10-fold cross validation results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
